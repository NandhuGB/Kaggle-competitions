{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T18:47:18.115741Z",
     "start_time": "2020-09-22T18:47:18.104033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing cached imports\n",
    "import src.preproccessing\n",
    "from importlib import reload\n",
    "reload(src.preproccessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load data/missing_value import DroppingMissingValueStrategy \n",
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Loading dataset from a specified filepath.\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T18:47:18.984418Z",
     "start_time": "2020-09-22T18:47:18.469381Z"
    }
   },
   "outputs": [],
   "source": [
    "df= load_data(\"./dataset/AB_NYC_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties of the dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns with missing values\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing>0]\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Name\n",
    "\n",
    "df_name_missed = df[df[\"name\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df[\"id\"].unique()) == len(df[\"id\"]):\n",
    "    print(\"every id is unique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p>The `name` and `host name` columns are nominal values. I dont want to consider these columns for out model.\n",
    " `name` might be useful on SEO basis. but i dont think it might make any difference on prices. i am dropping both columns</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"name\", \"host_name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling last_review and reviews_per_month page\n",
    "\n",
    "df_last_review_missed = df[df[\"last_review\"].isnull()]\n",
    "df_review_per_month_missed = df[df[\"reviews_per_month\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If last_review and review_per_month missing row are same. I am considering i dont have any review so far. I am repalcing null with 'zero'\n",
    "\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Missing Value strategies\n",
    "\n",
    "from src.preproccessing import missing_values\n",
    "missing_const = missing_values.FillConstMissingValuesStrategy(const = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = missing_const.handle(df =df, column=\"last_review\")\n",
    "df = missing_const.handle(df=df, column = \"reviews_per_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding suplicate data\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T18:47:28.695452Z",
     "start_time": "2020-09-22T18:47:28.417434Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"NO duplicates found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering categorical variables\n",
    "\n",
    "categories = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    unique = df[category].unique()\n",
    "    length  = len(unique)\n",
    "    print(f\"Unique categories in {category} has {len(unique)} unique values\")\n",
    "    if length< 10:\n",
    "        print(unique)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn_neighbourhoods = df[df['neighbourhood_group'] == \"Brooklyn\"]['neighbourhood'].unique().tolist()\n",
    "manhattan_neighbourhoods = df[df['neighbourhood_group'] == \"Manhattan\"]['neighbourhood'].unique().tolist()\n",
    "queens_neighbourhoods = df[df['neighbourhood_group'] == \"Queens\"]['neighbourhood'].unique().tolist()\n",
    "staten_neighbourhoods = df[df['neighbourhood_group'] == \"Staten Island\"]['neighbourhood'].unique().tolist()\n",
    "bronx_neighbourhoods = df[df['neighbourhood_group'] == \"Bronx\"]['neighbourhood'].unique().tolist()\n",
    "neighbourhoods = df[\"neighbourhood_group\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We have very few features. so i am going to use one hot encoding for `neighbourhood_group` and `room_type`</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Onehot encoding\n",
    "\n",
    "from src.preproccessing import encoding\n",
    "onehot_encoder = encoding.OneHotEncoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbourhood_group feature encoding\n",
    "print(categories[0])\n",
    "encoded_df = onehot_encoder.encode(df=df, column=categories[0])\n",
    "df.drop(labels=[categories[0]], axis=1, inplace =True)\n",
    "df = pd.concat([df, encoded_df], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# room_type onehot encoding\n",
    "\n",
    "print(categories[2])\n",
    "encoded_df = onehot_encoder.encode(df=df, column=categories[2])\n",
    "df.drop(labels=[categories[2]],axis=1)\n",
    "df = pd.concat([df,encoded_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>`neighbourhood` is have 221 unique value which comes under neighbourhood_groups. Distance to the neighbourhood going to be a new feature using `google maps distance matric api`</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Geocoding api keys\n",
    "\n",
    "df_api = pd.read_csv(\"geocoding_api.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting langtitude and latitude for neighbourhoods using openweathermap api\n",
    "# import requests\n",
    "\n",
    "# def get_lat_long(city):\n",
    "#     api_key = df_api[df_api[\"api\"]==\"openweather_map\"][\"api_key\"][0]\n",
    "#     limit = 1\n",
    "#     url = f\"http://api.openweathermap.org/geo/1.0/direct?q={city}, NY,US&limit={limit}&appid={api_key}\"\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code ==200:\n",
    "#         data =  response.json()\n",
    "#         print(f\"Geographical data for {city}:\")\n",
    "#         for entry in data:\n",
    "#             print(f\"Name: {entry['name']}, Latitude: {entry['lat']}, Longitude: {entry['lon']}\")\n",
    "#             return [city,(entry[\"lat\"], entry[\"lon\"])]\n",
    "#     else:\n",
    "#         print(f\"Error: Unable to fetch data (status code:{response.status_code})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Getting geocodes for all neighbourhood\n",
    "\n",
    "# unique_neighbourhood = df[\"neighbourhood\"].unique()\n",
    "# geo_code = {}\n",
    "# count = 1\n",
    "# for city in unique_neighbourhood:\n",
    "    \n",
    "#     print(f\"getting city {count}: {city}\")\n",
    "#     result = get_lat_long(city)\n",
    "#     if result != None:\n",
    "#         geo_code[city] = result[1]\n",
    "#     else:\n",
    "#         geo_code[city] = None\n",
    "#     count +=1\n",
    "\n",
    "# # storing collected data into csv file\n",
    "# df_geocode = pd.DataFrame(list(geo_code.items()), columns=['neighbourhood', 'geocode'])\n",
    "# df_geocode.to_csv('geo_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Opencage forward geocoding api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting geocodes for remaining neighbourhoods using opencagedata api\n",
    "# from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "# from pprint import pprint\n",
    "# api_key = df_api[df_api[\"api\"]==\"opencagedata\"][\"api_key\"][1]\n",
    "# geocoder = OpenCageGeocode(api_key)\n",
    "\n",
    "# def opencage(city, county):\n",
    "#     query = f\"{city}, {county}, New York, United states of America\"\n",
    "#     results = geocoder.geocode(query, countrycode=\"us\",limit =4)\n",
    "#     current = {}\n",
    "#     count = 1\n",
    "#     for result in results:\n",
    "#         if count ==1:\n",
    "#             current[\"best\"] = [result[\"formatted\"], result[\"geometry\"], result[\"confidence\"]]\n",
    "#         else:\n",
    "#             if current[\"best\"][2] < result[\"confidence\"]:\n",
    "#                 current[\"best\"] = [result[\"formatted\"], result[\"geometry\"], result[\"confidence\"]]\n",
    "#         count+=1\n",
    "\n",
    "#     return current[\"best\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geocode = {}\n",
    "# for neighbourhood in neighbourhoods:\n",
    "#     if neighbourhood ==\"Brooklyn\":\n",
    "#         current_group = brooklyn_neighbourhoods\n",
    "#     elif neighbourhood ==\"Manhattan\":\n",
    "#         current_group = manhattan_neighbourhoods\n",
    "#     elif neighbourhood ==\"Queens\":\n",
    "#         current_group = queens_neighbourhoods\n",
    "#     elif neighbourhood ==\"Staten Island\":\n",
    "#         current_group = staten_neighbourhoods\n",
    "#     else:\n",
    "#         current_group = bronx_neighbourhoods\n",
    "   \n",
    "#     for city in current_group:\n",
    "#         print(f\"current city: {city}\")\n",
    "#         result = opencage(city, neighbourhood)\n",
    "#         geocode[city] = result[1]\n",
    "#         print(f\"geocoded: {result[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_opencage_geocoded = pd.DataFrame(list(geocode.items()), columns=[\"neighbourhood\",\"geometry\"])\n",
    "# df_opencage_geocoded.to_csv(\"neighbourhood_opencage_geometry.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering - Feature `distance bw unit and neighbourhood`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pprint(current[\"best\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(results[0][\"formatted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = df[\"neighbourhood\"][0]\n",
    "\n",
    "origin = (df[\"latitude\"][0], df[\"longitude\"][0])\n",
    "mode = \"driving\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = get_distance(origin, destination, mode = mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We have latitude and longitude data. Even its metric data we cant use it bluntly. we can create new features like \"distance between subway and the unit\" and \"distance to nearest public transport\" and \"distance to city center\", \"distance to nearest airport\"</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T20:03:39.553700Z",
     "start_time": "2020-09-21T20:03:39.037325Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:30:45.490026Z",
     "start_time": "2020-09-21T19:30:45.478056Z"
    }
   },
   "outputs": [],
   "source": [
    "rfs=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:32:03.635109Z",
     "start_time": "2020-09-21T19:30:46.266130Z"
    }
   },
   "outputs": [],
   "source": [
    "rff=rfs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:32:06.701909Z",
     "start_time": "2020-09-21T19:32:03.638105Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict=rff.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:14.207105Z",
     "start_time": "2020-09-21T19:41:14.195099Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predic=pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:33.022736Z",
     "start_time": "2020-09-21T19:41:32.956878Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_map={0:dict(zip(list(range(1,len(cate)+1)),cate))}\n",
    "y_predic.replace(reverse_map,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:34.555748Z",
     "start_time": "2020-09-21T19:41:34.443660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the results in Csv\n",
    "data={'id':test.id,'country':y_predic[0]}\n",
    "pd.DataFrame(data).set_index('id').to_csv(r'submission files/submission_RF01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:36.680340Z",
     "start_time": "2020-09-21T19:41:36.620535Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score=pd.read_csv(r'submission files/submission_RF01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:43:55.531204Z",
     "start_time": "2020-09-21T19:43:55.513250Z"
    }
   },
   "outputs": [],
   "source": [
    "sv=svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.802638Z",
     "start_time": "2020-09-10T17:36:45.664Z"
    }
   },
   "outputs": [],
   "source": [
    "svr=rfs.fit(x_train_f,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.803602Z",
     "start_time": "2020-09-10T17:36:45.668Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict=svr.predict(x_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.804600Z",
     "start_time": "2020-09-10T17:36:45.671Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.805635Z",
     "start_time": "2020-09-10T17:36:45.674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the results in Csv\n",
    "data={'Id':range(1461,2920),'SalePrice':y_predict}\n",
    "pd.DataFrame(data).set_index('Id').to_csv(r'submission files/submission_RF02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.806630Z",
     "start_time": "2020-09-10T17:36:45.676Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score=pd.read_csv(r'submission files/submission_RF01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.807592Z",
     "start_time": "2020-09-10T17:36:45.679Z"
    }
   },
   "outputs": [],
   "source": [
    "a=best_score['SalePrice']-y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.808624Z",
     "start_time": "2020-09-10T17:36:45.684Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig,ax1=plt.subplot(1,1)\n",
    "sns.distplot(a,bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.809621Z",
     "start_time": "2020-09-10T17:36:45.690Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score['new']=y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.810583Z",
     "start_time": "2020-09-10T17:36:45.694Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(best_score[['SalePrice','new']].corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:45:21.956390Z",
     "start_time": "2020-09-21T19:45:21.942390Z"
    }
   },
   "outputs": [],
   "source": [
    "KNN=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-21T19:45:47.421Z"
    }
   },
   "outputs": [],
   "source": [
    "knn=KNN.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.803602Z",
     "start_time": "2020-09-10T17:36:45.668Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict=knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:14.207105Z",
     "start_time": "2020-09-21T19:41:14.195099Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predic=pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:33.022736Z",
     "start_time": "2020-09-21T19:41:32.956878Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_map={0:dict(zip(list(range(1,len(cate)+1)),cate))}\n",
    "y_predic.replace(reverse_map,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:34.555748Z",
     "start_time": "2020-09-21T19:41:34.443660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the results in Csv\n",
    "data={'id':test.id,'country':y_predic[0]}\n",
    "pd.DataFrame(data).set_index('id').to_csv(r'submission files/submission_KNN01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.804600Z",
     "start_time": "2020-09-10T17:36:45.671Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.805635Z",
     "start_time": "2020-09-10T17:36:45.674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the results in Csv\n",
    "data={'Id':range(1461,2920),'SalePrice':y_predict}\n",
    "pd.DataFrame(data).set_index('Id').to_csv(r'submission files/submission_RF02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.806630Z",
     "start_time": "2020-09-10T17:36:45.676Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score=pd.read_csv(r'submission files/submission_RF01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.807592Z",
     "start_time": "2020-09-10T17:36:45.679Z"
    }
   },
   "outputs": [],
   "source": [
    "a=best_score['SalePrice']-y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.808624Z",
     "start_time": "2020-09-10T17:36:45.684Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig,ax1=plt.subplot(1,1)\n",
    "sns.distplot(a,bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.809621Z",
     "start_time": "2020-09-10T17:36:45.690Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score['new']=y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.810583Z",
     "start_time": "2020-09-10T17:36:45.694Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(best_score[['SalePrice','new']].corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T20:03:45.622970Z",
     "start_time": "2020-09-21T20:03:45.609965Z"
    }
   },
   "outputs": [],
   "source": [
    "xg=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T20:14:45.653119Z",
     "start_time": "2020-09-21T20:04:04.201806Z"
    }
   },
   "outputs": [],
   "source": [
    "xgf=xg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T17:36:45.803602Z",
     "start_time": "2020-09-10T17:36:45.668Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict=xgf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:14.207105Z",
     "start_time": "2020-09-21T19:41:14.195099Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predic=pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:33.022736Z",
     "start_time": "2020-09-21T19:41:32.956878Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_map={0:dict(zip(list(range(1,len(cate)+1)),cate))}\n",
    "y_predic.replace(reverse_map,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T19:41:34.555748Z",
     "start_time": "2020-09-21T19:41:34.443660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the results in Csv\n",
    "data={'id':test.id,'country':y_predic[0]}\n",
    "pd.DataFrame(data).set_index('id').to_csv(r'submission files/submission_XG01.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
